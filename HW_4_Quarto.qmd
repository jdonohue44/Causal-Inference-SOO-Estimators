---
title: "Design and Analysis of Online Experiments Homework 4: Causal Inference using Selection on Observables Design (SOO)"
format: html
editor: visual
---

## Introduction
In this exercise, I implement various estimators under the selection on observables (SOO) design using a simulated data set. The results emphasize the importance of meeting SOO assumptions for observational causal inference. When the assumption is violated, we observe biased and less precise estimates of the ATE. However, more sophisticated methods like doubly robust estimation can help mitigate some of these issues, providing more reliable estimates even when the model is not perfectly specified. This underscores the importance of careful consideration of potential confounders and the use of appropriate statistical techniques in observational causal inference studies.

## Estimators
- Estimator 0: Unadjusted means
- Estimator 1.1: Regression adjustment with full control variables
- Estimator 1.2: Regression adjustment with partial control variables
- Estimator 2.1: Conditioning on propensity score with full control variables
- Estimator 2.2: Conditioning on propensity score with partial control variables
- Estimator 3.1: Re-weighting based on propensity score with full control variables
- Estimator 3.2: Re-weighting based on propensity score with partial control variables
- Estimator 4.1: Blocking based on propensity score with full control variables
- Estimator 4.2: Blocking based on propensity score with partial control variables
- Estimator 5.1: Doubly robust estimator with full control variables
- Estimator 5.2: Doubly robust estimator with partial control variables

## Bootstrap
Draw 200 bootstrapped samples (with replacement) of size 500 from this simulated dataset (this will mimic the process of random sampling from a population) and estimate the average treatment effect (ATE) using the estimators for each bootstrapped sample.

```{r, message=FALSE, warning=FALSE, error=FALSE}
library(dplyr)
library(tidyr)
library(boot)
library(stats)

# Function to perform bootstrapping
bootstrap_and_run_estimator <- function(data, estimator_function, n_bootstrap = 200, sample_size = 500) {
  results <- replicate(n_bootstrap, {
    # Sample with replacement
    sample_data <- data[sample(nrow(data), sample_size, replace = TRUE), ]
    # Apply estimator_0
    estimator_function(sample_data)
  })
  return(results)
}
```

## Load Data
```{r, message=FALSE, warning=FALSE, error=FALSE}
data <- read.csv("homework4.csv")
```

## Run Estimators
```{r, message=FALSE, warning=FALSE, error=FALSE}
source("Estimator_Functions.R")

set.seed(123)  # for reproducibility

# Estimator 0
results_0 <- bootstrap_and_run_estimator(data, estimator_0)
mean_ate_0 <- mean(results_0)
ci_0 <- quantile(results_0, c(0.025, 0.975))

# Estimator 1.1
results_1_1 <- bootstrap_and_run_estimator(data, estimator_1_1)
mean_ate_1_1 <- mean(results_1_1)
ci_1_1 <- quantile(results_1_1, c(0.025, 0.975))

# Estimator 1.2
results_1_2 <- bootstrap_and_run_estimator(data, estimator_1_2)
mean_ate_1_2 <- mean(results_1_2)
ci_1_2 <- quantile(results_1_2, c(0.025, 0.975))

# Estimator 2.1
results_2_1 <- bootstrap_and_run_estimator(data, estimator_2_1)
mean_ate_2_1 <- mean(results_2_1)
ci_2_1 <- quantile(results_2_1, c(0.025, 0.975))

# Estimator 2.2
results_2_2 <- bootstrap_and_run_estimator(data, estimator_2_2)
mean_ate_2_2 <- mean(results_2_2)
ci_2_2 <- quantile(results_2_2, c(0.025, 0.975))

# Estimator 3.1
results_3_1 <- bootstrap_and_run_estimator(data, estimator_3_1)
mean_ate_3_1 <- mean(results_3_1)
ci_3_1 <- quantile(results_3_1, c(0.025, 0.975))

# Estimator 3.2
results_3_2 <- bootstrap_and_run_estimator(data, estimator_3_2)
mean_ate_3_2 <- mean(results_3_2)
ci_3_2 <- quantile(results_3_2, c(0.025, 0.975))

# Estimator 4.1
results_4_1 <- bootstrap_and_run_estimator(data, estimator_4_1)
mean_ate_4_1 <- mean(results_4_1)
ci_4_1 <- quantile(results_4_1, c(0.025, 0.975))

# Estimator 4.2
results_4_2 <- bootstrap_and_run_estimator(data, estimator_4_2)
mean_ate_4_2 <- mean(results_4_2)
ci_4_2 <- quantile(results_4_2, c(0.025, 0.975))

# Estimator 5.1
results_5_1 <- bootstrap_and_run_estimator(data, estimator_5_1)
mean_ate_5_1 <- mean(results_5_1)
ci_5_1 <- quantile(results_5_1, c(0.025, 0.975))

# Estimator 5.2
results_5_2 <- bootstrap_and_run_estimator(data, estimator_5_2)
mean_ate_5_2 <- mean(results_5_2)
ci_5_2 <- quantile(results_5_2, c(0.025, 0.975))
```

## Problem 1: Resulting Mean Average Treatment Effect (ATE) and Confidence Interval (CI) of Estimators

| Estimator | Mean of ATE | 95% CI of ATE |
|---------|:-----|------:|:------:|
| Estimator 0: Unadjusted means | `r mean_ate_0` | `r ci_0` | 
| Estimator 1.1: Regression adjustment with full control variables | `r mean_ate_1_1` | `r ci_1_1` | 
| Estimator 1.2: Regression adjustment with partial control variables  | `r mean_ate_1_2` | `r ci_1_2` | 
| Estimator 2.1: Conditioning on propensity score with full control variables | `r mean_ate_2_1` | `r ci_2_1` | 
| Estimator 2.2: Conditioning on propensity score with partial control variables | `r mean_ate_2_2` | `r ci_2_2` |
| Estimator 3.1: Re-weighting based on propensity score with full control variables | `r mean_ate_3_1` | `r ci_3_1` |
| Estimator 3.2: Re-weighting based on propensity score with partial control variables | `r mean_ate_3_2` | `r ci_3_2` |
| Estimator 4.1: Blocking based on propensity score with full control variables | `r mean_ate_4_1` | `r ci_4_1` |
| Estimator 4.2: Blocking based on propensity score with partial control variables | `r mean_ate_4_2` | `r ci_4_2` |
| Estimator 5.1: Doubly robust estimator with full control variables | `r mean_ate_5_1` | `r ci_5_1` |
| Estimator 5.2: Doubly robust estimator with partial control variables | `r mean_ate_5_2` | `r ci_5_2` |

## Problem 2: Plot of ATE estimate distributions for Correctly Specified Estimators 0, 1.2, 2.2, 3.2, 4.2, 5.2.
```{r}
library(ggplot2)

plot_data <- tibble(
  estimator_0 = results_0,
  estimator_1_1 = results_1_1,
  estimator_2_1 = results_2_1,
  estimator_3_1 = results_3_1,
  estimator_4_1 = results_4_1,
  estimator_5_1 = results_5_1
) |>
  pivot_longer(cols = everything(), names_to = "estimator", values_to = "ate")

# Create the plot
ggplot(plot_data, aes(x = ate, fill = estimator)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  labs(title = "Distribution of ATE Estimates (Correctly Specified Models)",
       x = "Average Treatment Effect (ATE)",
       y = "Density") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2") +
  theme(legend.position = "bottom")
```

## Problem 3: Plot of ATE estimate distributions for Incorrectly Specified Estimators 0, 1.2, 2.2, 3.2, 4.2, 5.2.
```{r}
library(ggplot2)

plot_data <- tibble(
  estimator_0 = results_0,
  estimator_1_2 = results_1_2,
  estimator_2_2 = results_2_2,
  estimator_3_2 = results_3_2,
  estimator_4_2 = results_4_2,
  estimator_5_2 = results_5_2
) |>
  pivot_longer(cols = everything(), names_to = "estimator", values_to = "ate")

# Create the plot
ggplot(plot_data, aes(x = ate, fill = estimator)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  labs(title = "Distribution of ATE Estimates (Incorrectly Specified Models)",
       x = "Average Treatment Effect (ATE)",
       y = "Density") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2") +
  theme(legend.position = "bottom")
```

## Problem 4: Compare the results between the correctly specified models and the incorrectly specified models. What is learned about the impact of the violation of SOO design assumptions?

### Bias
When SOO is violated (i.e., not all relevant confounders are controlled for), we see substantial bias in the ATE estimates. This is evident in the overestimation of ATE in partially specified models. Correctly specified models (1.1, 2.1, 3.1, 4.1, 5.1) consistently produce mean ATE estimates closer to the true ATE of 1. Incorrectly specified models (0, 1.2, 2.2, 3.2, 4.2) tend to overestimate the ATE, with means further from 1.The unadjusted means (Estimator 0) show significant bias, highlighting the importance of controlling for confounding variables.

### Impact of SOO violation
Partial control variable models (1.2, 2.2, 3.2, 4.2) consistently overestimate the ATE, demonstrating the impact of omitted variable bias when the SOO assumption is violated.

### Robustness of methods

Propensity score methods (2.1, 3.1, 4.1) perform well when correctly specified but are sensitive to misspecification. The doubly robust estimator (5.2) performs notably well even when partially misspecified, with a mean ATE (1.0300482) very close to the correctly specified version (5.1: 1.0660079).

## Conclusion
The results emphasize the importance of meeting the Selection of Observables (SOO) assumptions for observational causal inference. When the assumption is violated, we observe biased and less precise estimates of the ATE. However, more sophisticated methods like doubly robust estimation can help mitigate some of these issues, providing more reliable estimates even when the model is not perfectly specified. This underscores the importance of careful consideration of potential confounders and the use of appropriate statistical techniques in observational causal inference studies.